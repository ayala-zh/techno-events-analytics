# RavePulse â€“ Techno Events Analytics
ğŸ“Œ Project Overview
Our company, RavePulse, is a data-driven platform for techno music enthusiasts.
It tracks events, artists, and users' preferences worldwide, providing insights into:

ğŸŒ Popular event locations â€“ Find out which cities host the most raves.
ğŸ¶ Most-followed artists â€“ Discover trending DJs and performers.
ğŸ‘¥ User attendance trends â€“ See how participation changes over time.
ğŸ¼ Genre preferences per region â€“ Understand what sound the crowd wants.
â­ Event ratings and feedback â€“ Measure audience satisfaction.

The goal of this project is to build a complete analytics solution using:

- **SQL** â€“ For complex business-oriented queries
- **Python** â€“ To automate data processing and create visualizations
- **Apache Superset** â€“ To create interactive visual dashboards
- **Grafana** â€“ For real-time monitoring and alerting

This helps event organizers plan better events, target the right audience, and increase overall engagement.

## ğŸ—„ Database Schema
RavePulse is powered by a relational database with the following main tables:

- **users** ğŸ‘¤ â€“ stores user information (id, name, age, city, country)
- **events** ğŸŸ â€“ stores event details (id, name, date, venue, genre)
- **eventhistory** ğŸ“œ â€“ a join table connecting users and events (attendance, rating, interest)

This schema allows us to explore who attended what, when, and where, making it easy to build meaningful insights.

## ğŸ“Š Business Insights & Queries
Our analytics include:

- **Top Venues** â€“ Find the most frequently used venues
- **Monthly Event Trends** â€“ See which months are the most active
- **City Participation Rates** â€“ Understand which cities have the highest engagement
- **Average Ratings per Event** â€“ Detect events that left the best impression
- **Active Users** â€“ Identify loyal participants who attend the most raves
- **Genre Popularity Analysis** â€“ Measure which genres dominate the techno scene

All queries are stored in `queries.sql` and can be executed automatically via Python.

## ğŸ Python Automation & Visualizations
We built a comprehensive Python script that:

- Connects to the PostgreSQL database
- Reads all SQL queries from `queries.sql`
- Executes them in sequence
- Prints results in a clean, readable format
- **Generates multiple interactive visualizations**:
  - ğŸ“Š **Pie Chart** â€“ Genre distribution across events
  - ğŸ“ˆ **Bar Chart** â€“ Event attendance by city
  - â¡ï¸ **Horizontal Bar Chart** â€“ Top venues by number of events
  - ğŸ“‰ **Line Chart** â€“ Monthly event trends over time
  - ğŸ“‹ **Histogram** â€“ User age distribution
  - âœ¨ **Scatter Plot** â€“ Event ratings vs attendance correlation

This ensures we can rerun the entire analysis with a single command, even if new data is added to the database.

## ğŸ“Š Advanced Analytics with Apache Superset
We've created **interactive dashboards** in Apache Superset featuring:

- **Dynamic Filters** â€“ Filter data by date range, city, genre, and venue
- **Custom Formulas** â€“ Calculate advanced metrics like engagement rate and satisfaction index
- **Advanced Visualizations**:
  - Heatmaps for event density by location
  - Time series analysis for seasonal trends
  - Comparative analysis across regions
  - Real-time audience sentiment tracking

The dashboards **update automatically** when the database changes, providing always-current insights.

## ğŸ“Š Real-time Monitoring with Grafana
We've integrated **Grafana** for real-time monitoring:

- **Live Event Metrics** â€“ Track attendance, ratings, and engagement in real-time
- **Custom Alerts** â€“ Get notified about trending events or low-rated venues
- **Performance Dashboards** â€“ Monitor system health and data pipeline status
- **Automated Reporting** â€“ Scheduled reports sent to stakeholders

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- PostgreSQL
- Apache Superset
- Grafana


---

## ğŸš€ Getting Started

1. **Clone this repository:**
   ```bash
   git clone (https://github.com/ayala-zh/techno-events-analytics)
   cd techno-events-analytics
2. **Install dependencies**
Make sure you have Python 3.8+ installed, then install the required packages with:
   ```bash
   pip install -r requirements.txt

3. **Set up the database**
Open psql
   ```bash
   psql -U postgres
Create and populate the database
CREATE DATABASE techno_events_db;
\c techno_events_db
\i queries.sql

5. **Configure Project**
   - Open `main.py`
   - Update your database password if needed:
     ```python
     conn = psycopg2.connect(
         host="localhost",
         user="postgres",
         password="your_password",
         dbname="techno_events_db"
     )
     ```
6. **Run Script**
   ```bash
   python Main.py

